{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71f5d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://navercomp.wisereport.co.kr/v2/ETF/index.aspx?cmp_cd=133690\n"
     ]
    }
   ],
   "source": [
    "# [1] 코스피 지수 구성종목 분석 페이지를 시가총액 순으로 긁어오자.\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def create_analysis_link(link):\n",
    "    new = 'https://finance.naver.com' + link\n",
    "    return 'https://finance.naver.com' + link[:6] + 'coinfo' + link[10:]\n",
    "\n",
    "\n",
    "links = [] # 최종적인 링크들을 담을 테이블\n",
    "\n",
    "# 시가총액 1~200위 페이지\n",
    "for page in range(1,5):\n",
    "    html = urlopen('https://finance.naver.com/sise/sise_market_sum.naver?&page='+str(page))\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    rankings = bs.findAll('a',{'href' : re.compile('^(/item/main.)')})\n",
    "\n",
    "    # 각 종목별 페이지로 연결\n",
    "    for ranking in rankings:\n",
    "            if 'href' in ranking.attrs:\n",
    "                midLink = str(create_analysis_link(ranking.attrs['href']))\n",
    "                \n",
    "                # 종목별 페이지 속의 '재무분석' 페이지로 연결\n",
    "                html = urlopen(\"{}\".format(midLink))\n",
    "                bs = BeautifulSoup(html,'html.parser')\n",
    "                link = bs.find('div', {'class' : 'section inner_sub'}).find('iframe')\n",
    "                \n",
    "                if 'src' in link.attrs:\n",
    "                    financialLink = link.attrs['src']\n",
    "                    links.append(financialLink)\n",
    "                    \n",
    "print(links[140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c9b6e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] 어떤 자료들을 긁어올 것인지 '크롤링 모델'을 설정하자.\n",
    "\n",
    "def unit_conversion(num):\n",
    "    return round(float(num.replace(\",\",\"\")))*10**8\n",
    "\n",
    "class Content:\n",
    "    \n",
    "# bs_arr = [title, [ EPS, BPS, PER, 업종PER, PBR, 현금배당수익률]]\n",
    "# sel_arr = [market_cap, per_arr, current_asset, current_liability, cashable_asset]\n",
    "    \n",
    "    # 데이터 입력받기\n",
    "    def __init__(self, bs_arr):\n",
    " \n",
    "        # BeautifulSoup으로 긁어올 정보들 (추후에 정리)\n",
    "        self.title = bs_arr[0]\n",
    "        self.eps = bs_arr[1][0]\n",
    "        self.bps = bs_arr[1][1]\n",
    "        self.per = bs_arr[1][2]\n",
    "        self.per_industry = bs_arr[1][3]\n",
    "        self.pbr = bs_arr[1][4]\n",
    "        self.dividend_rate = bs_arr[1][5]\n",
    "    \n",
    "    def input_sel(self, sel_arr):\n",
    "    \n",
    "        # Selenium으로 긁어올 정보들 (추후에 정리)\n",
    "        self.market_cap = sel_arr[0]\n",
    "        self.per_average = sel_arr[1]\n",
    "        self.current_asset = sel_arr[2]\n",
    "        self.current_liability = sel_arr[3]\n",
    "        self.cashable_asset = sel_arr[4]\n",
    "        \n",
    "    # return\n",
    "    def return_data(self):\n",
    "        data = [self.title, self.market_cap, self.per, self.per_average, self.per_industry, self.dividend_rate,\n",
    "        self.current_asset, self.current_liability, self.cashable_asset]\n",
    "        return data\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9168f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] BeautifulSoup으로 긁어오기.\n",
    "\n",
    "def make_name(arr):\n",
    "    return arr[6][12:] + ' ' + 'ETF'\n",
    "\n",
    "def extract_name(name):\n",
    "    i = -1\n",
    "    for i in range(1, len(name)):\n",
    "        if name[-i] == '(':\n",
    "            name = name[-i+1:-1]\n",
    "            break\n",
    "    return name\n",
    "\n",
    "# writer.writerow(('종목 이름', 'EPS', 'BPS', 'PER', '업종PER', 'PBR', '현금배당수익률'))\n",
    "# rank, title, basic data(리스트)\n",
    "\n",
    "finance_data = [0] * 201\n",
    "\n",
    "i=1\n",
    "for one in links[:10]:\n",
    "    html = urlopen(\"{}\".format(one))\n",
    "    bs = BeautifulSoup(html, 'html.parser')\n",
    "    try:\n",
    "        # title 가져오기\n",
    "        title = bs.find('title').get_text()\n",
    "        title = extract_name(title) # 형식에 맞게 수정\n",
    "            \n",
    "        # 재무정보 가져오기\n",
    "        table = bs.findAll('table',{'class' : 'cmp-table'})[0]\n",
    "        rows = table.findAll('tr')[2].findAll('dt')\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "                \n",
    "        # 필요없는 정보면 continue\n",
    "            if row.get_text() == '12월 결산': \n",
    "                continue\n",
    "                    \n",
    "            temp = row.get_text().split()\n",
    "            if len(temp) == 1:\n",
    "                temp.append('N/A')\n",
    "            data.append(temp[1])\n",
    "                \n",
    "    # ETF일 때.        \n",
    "    except IndexError as e:\n",
    "        bs = bs.findAll('script', {'type':'text/javascript'})[2]\n",
    "        arr = list(map(str,str(bs).split()))\n",
    "            \n",
    "        title = 'ETF'\n",
    "        data = ['N/A', 'N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n",
    "        \n",
    "    finally:\n",
    "        bs_arr = [title, data]\n",
    "        content = Content(bs_arr)\n",
    "        finance_data[i] = content\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "827764cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dck\\AppData\\Local\\Temp/ipykernel_18408/3285596659.py:16: DeprecationWarning: use options instead of chrome_options\n",
      "  browser = webdriver.Chrome(chrome_options=options)\n",
      "C:\\Users\\dck\\AppData\\Local\\Temp/ipykernel_18408/3285596659.py:32: DeprecationWarning: find_element_by_link_text is deprecated. Please use find_element(by=By.LINK_TEXT, value=link_text) instead\n",
      "  browser.find_element_by_link_text(\"재무분석\").click()\n",
      "C:\\Users\\dck\\AppData\\Local\\Temp/ipykernel_18408/3285596659.py:33: DeprecationWarning: find_element_by_link_text is deprecated. Please use find_element(by=By.LINK_TEXT, value=link_text) instead\n",
      "  browser.find_element_by_link_text(\"재무상태표\").click()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['삼성전자', '4,125,120억원', '11.96', 13.62, '10.64', '2.09%', '2,181,631.9', '881,171.3', '390,314.2']\n",
      "['LG에너지솔루션', '1,001,520억원', '108.01', 89.9, '77.54', 'N/A', 'N/A', 'N/A', 'N/A']\n",
      "['SK하이닉스', '844,483억원', '8.79', 14.06, '10.64', '1.33%', '268,704.5', '147,693.6', '50,579.8']\n",
      "['NAVER', '550,385억원', '3.34', 34.51, '5.94', '0.15%', '55,278.8', '39,233.2', '27,814.0']\n",
      "['삼성바이오로직스', '542,553억원', '139.51', 267.52, '83.29', 'N/A', 'N/A', 'N/A', 'N/A']\n",
      "['삼성전자', '4,125,120억원', '11.96', 13.62, '10.64', '2.09%', '2,181,631.9', '881,171.3', '390,314.2']\n",
      "['카카오', '472,890억원', '33.84', 127.17, '5.94', '0.05%', '81,021.9', '52,461.2', '52,315.0']\n",
      "['삼성SDI', '403,648억원', '35.32', 41.36, '77.54', '0.17%', '74,449.1', '64,612.9', '23,256.9']\n",
      "['현대차', '380,329억원', '9.97', 18.68, '7.31', '2.81%', '533,127.6', '642,367.9', '127,955.5']\n",
      "['LG화학', '369,198억원', '11.16', 50.6, '8.63', '2.29%', '204,138.2', '150,621.0', '37,608.3']\n"
     ]
    }
   ],
   "source": [
    "# [4] Selenium으로 긁어오기.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time\n",
    "\n",
    "# headless 설정\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "\n",
    "i=1\n",
    "for one in links[:10]:\n",
    "    try:\n",
    "        # 브라우저 생성\n",
    "        browser = webdriver.Chrome(chrome_options=options)\n",
    "        browser.get('{}'.format(one))\n",
    "\n",
    "        # 시가총액 구하기\n",
    "        elementXpath = '//*[@summary=\"기업의 기본적인 시세정보(주가/전일대비/수익률,52주최고/최저,액면가,거래량/거래대금,시가총액,유동주식비율,외국인지분율,52주베타,수익률(1M/3M/6M/1Y))를 제공합니다.\"]/tbody/tr[5]/td'\n",
    "        market_cap = browser.find_element(by=By.XPATH, value = elementXpath).text\n",
    "\n",
    "        # per 평균 구하기\n",
    "        browser.find_element(by=By.XPATH, value = '//*[@title=\"연간\"]').click()\n",
    "\n",
    "        elementXpath = '//table[@summary=\"주요재무정보를 제공합니다.\"][2]/tbody/tr[27]'\n",
    "        element = browser.find_element(by=By.XPATH, value = elementXpath)\n",
    "        per_table = [float(x) for x in element.text.split()[1:6] if x != 'N/A']\n",
    "        per_arr = round(sum(per_table)/len(per_table), 2)\n",
    "\n",
    "        # 유동자산/유동부채 구하기\n",
    "        browser.find_element_by_link_text(\"재무분석\").click()\n",
    "        browser.find_element_by_link_text(\"재무상태표\").click()\n",
    "\n",
    "        # Loading\n",
    "        time.sleep(1)\n",
    "\n",
    "        # 참고로 Xpath는 시작점이 0이 아니라 1이다.\n",
    "        try:\n",
    "            elementXpath = '//table[@summary=\"IFRS연결 연간 재무 정보를 제공합니다.\"][2]/tbody/tr[2]/td[6]'\n",
    "            current_asset = browser.find_element(by=By.XPATH, value = elementXpath).text\n",
    "        except:\n",
    "            current_asset = 'N/A'\n",
    "\n",
    "        try:\n",
    "            elementXpath = '//table[@summary=\"IFRS연결 연간 재무 정보를 제공합니다.\"][2]/tbody/tr[128]/td[6]'\n",
    "            current_liability = browser.find_element(by=By.XPATH, value = elementXpath).text\n",
    "        except:\n",
    "            current_liability = 'N/A'\n",
    "\n",
    "        # 현금 및 현금성 자산 구하기\n",
    "        try:\n",
    "            elementXpath = '//table[@summary=\"IFRS연결 연간 재무 정보를 제공합니다.\"][2]/tbody/tr[47]/td[6]'\n",
    "            cashable_asset = browser.find_element(by=By.XPATH, value = elementXpath).text\n",
    "        except:\n",
    "            cashable_asset = 'N/A'\n",
    "\n",
    "        # 객체화\n",
    "        sel_arr = [market_cap, per_arr, current_asset, current_liability, cashable_asset]\n",
    "        \n",
    "    # ETF일 때. \n",
    "    except: \n",
    "        sel_arr = ['N/A', 'N/A', 'N/A', 'N/A', 'N/A']\n",
    "\n",
    "    finally:\n",
    "        finance_data[i].input_sel(sel_arr)\n",
    "        finance_data[i] = finance_data[i].return_data()\n",
    "        browser.quit()\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "#. return_data()의 성질\n",
    "[self.title, self.market_cap, self.per, self.per_average, self.per_industry, self.dividend_rate,\n",
    "        self.current_asset, self.current_liability, self.cashable_asset]\n",
    "\"\"\"\n",
    "for data in finance_data[1:11]:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "90f7ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvFile = open('테스트파일.csv', 'wt+', newline = '')\n",
    "writer = csv.writer(csvFile)\n",
    "\n",
    "writer.writerow(('기업 이름', '시가총액(억)', 'PER', '5년 평균 PER', '업종 평균 PER',\n",
    "                '현금배당수익률','유동자산(억)','유동부채(억)','현금 및 현금성 자산(억)'))\n",
    "\n",
    "try:\n",
    "    for one in finance_data[1:11]:\n",
    "        writer.writerow(one)\n",
    "        \n",
    "finally:\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15749df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "매우 뿌듯하다. \n",
    "수 많은 에러와 역경을 뚫고 원하던 결과물을 냈다...\n",
    "물론 부족한 점이 너무 많다.\n",
    "\n",
    "(1) 클래스가 너무 잡다해서 다른 사람이 알아볼 수가 없다.\n",
    "(2) 클래스 뿐 아니라 변수명이나 구조도 너무 복잡해서 다른 사람이 읽을 수가 없다. 주석도 필요하다.\n",
    "(3) 셀레니움 크롤링은 너무 오래걸린다.\n",
    "단순히 셀레니움만 쓸 것이 아니라, 셀레니움으로 띄우고 뷰티풀솦으로 크롤링할 방법을 찾아야 한다. \n",
    "몇 배는 빨라질 것이다. \n",
    "\n",
    "하지만 문제는 '재무상태표'를 클릭한 상태로 html 파일을 뷰티풀 솦으로 보내도 이상하게 \n",
    "해당 html은 '재무상태표'가 아니라 '포괄손익계산서'가 담긴 html을 띄운다.. 어찌된 일일까?\n",
    "좀 뒤적여본 결과, 아마도 자바스크립트 상의 내용인 것 같다. \n",
    "\n",
    "대충 보더라도 해결해야할 부분이 3가지이다.\n",
    "우선 오늘밤에 한번 200위까지 크롤링을 돌려보고 다시 한번 리뷰를 해보도록 하겠다.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
