{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cccc2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국내 코스피 50개 구성항목 링크\n",
      "https://finance.naver.com/item/coinfo.naver?code=323410\n"
     ]
    }
   ],
   "source": [
    "# 코스피 지수 구성 종목들의 링크 테이블 만들기.\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import ssl\n",
    "\n",
    "def create_analysis_link(link):\n",
    "    new = 'https://finance.naver.com' + link\n",
    "    return 'https://finance.naver.com' + link[:6] + 'coinfo' + link[10:]\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "html = urlopen('https://finance.naver.com/sise/sise_market_sum.naver?', context = context)\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "links = bs.findAll('a',{'href' : re.compile('^(/item/main.)')})\n",
    "\n",
    "table = []\n",
    "for link in links:\n",
    "        if 'href' in link.attrs:\n",
    "            table.append(link.attrs['href'])\n",
    "    \n",
    "print(\"국내 코스피 50개 구성항목 링크\")\n",
    "            \n",
    "for i in range(len(table)):\n",
    "    table[i] = str(create_analysis_link(table[i]))\n",
    "\n",
    "\"\"\"\n",
    "우선 정보를 추출하여 저장하는 사이클 하나를 돈 이후에는,\n",
    "이 부분을 함수로 만들어서 50개 이상의 항목들을 쭉 긁어올 수 있도록 만들어 놓자.\n",
    "코드들의 부분 부분을 쭉 업그레이드를 해나갈 예정이다.\n",
    "\"\"\"\n",
    "\n",
    "print(table[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a553aafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://navercomp.wisereport.co.kr/v2/company/c1010001.aspx?cmp_cd=323410\n"
     ]
    }
   ],
   "source": [
    "# 얻어온 재무 분석 링크에서 javascript 링크 따오기.\n",
    "\n",
    "array = []\n",
    "for one in table:\n",
    "    html = urlopen(\"{}\".format(one), context = context)\n",
    "    bs = BeautifulSoup(html,'html.parser')\n",
    "    link = bs.find('div', {'class' : 'section inner_sub'}).find('iframe')\n",
    "    if 'src' in link.attrs:\n",
    "        goal = link.attrs['src']\n",
    "        array.append(goal)\n",
    "        \n",
    "print(array[13])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d708485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the end...\n"
     ]
    }
   ],
   "source": [
    "# 따온 링크에서 원하는 정보 추출하기\n",
    "\n",
    "import csv\n",
    "\n",
    "def extract_name(name):\n",
    "    a, b, c, d, name = name.split()\n",
    "    i = -1\n",
    "    for i in range(1, len(name)):\n",
    "        if name[-i] == '(':\n",
    "            name = name[-i+1:-1]\n",
    "            break\n",
    "    return name\n",
    "\n",
    "csvFile = open('Finance.csv', 'wt+')\n",
    "writer = csv.writer(csvFile)\n",
    "try:\n",
    "\n",
    "    writer.writerow(('기업 이름', 'EPS', 'BPS', 'PER', '업종PER', 'PBR', '현금배당수익률'))\n",
    "    \n",
    "    for one in array:\n",
    "        html = urlopen(\"{}\".format(one), context =context)\n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        table = bs.findAll('table',{'class' : 'cmp-table'})[0]\n",
    "        rows = table.findAll('tr')[2].findAll('dt')\n",
    "\n",
    "        name = bs.find('title').get_text()\n",
    "        name = extract_name(name)\n",
    "\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            if row.get_text() == '12월 결산':\n",
    "                continue\n",
    "            temp = row.get_text().split()\n",
    "            if len(temp) == 1:\n",
    "                temp.append('N/A')\n",
    "            data.append(temp[1])\n",
    "        \n",
    "        writer.writerow((name, data[0],data[1],data[2],data[3],data[4],data[5]))\n",
    "    \n",
    "finally:\n",
    "    csvFile.close()\n",
    "    \n",
    "print('the end...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "나름 소기의 목적을 달성했다.\n",
    "\n",
    "여러 가지 과정을 통해 결국은 코스피 시총 1위부터 50위까지의 재무정보를 추출했고,\n",
    "엑셀파일로도 깔끔하게 완성했다.\n",
    "\n",
    "하지만, 페이지만 다른 51위 부터는 무엇때문인지 인덱스 오류가 생긴다.\n",
    "아무래도 현금배당률이 제시가 안되어있다던지 등의 문제인 것 같은데, \n",
    "웹은 변수 투성이라는게 이런 말인가 싶다.\n",
    "\n",
    "오히려 좋다. 에러처리를 직접 실습해볼 기회다!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
